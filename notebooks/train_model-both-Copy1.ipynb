{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Contents\n",
    "- Process data into one-hot encoded sequence vectors and targets.\n",
    "- Break into train, validation, and test sets.\n",
    "- Perform a modest hyper-parameter search.\n",
    "- Conclude that a variety of hyperparameters result in similar performance.\n",
    "- Train and save a model to use in rest of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from genome import Genome\n",
    "genome = Genome('../anno/hg19.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "introns = {}\n",
    "with open('../preprocessing/introns_to_mercer.tsv') as fp:\n",
    "    for line in fp:\n",
    "        chrom, start, end, _, pos, strand, _, bp = line.split('\\t')[:8]\n",
    "        bp, start, end = int(bp), int(start), int(end)\n",
    "        \n",
    "        three = end if strand == '+' else start  \n",
    "        key = (chrom, three, strand)\n",
    "        \n",
    "        if not 5 < abs(bp - three) < 60:\n",
    "            bp = -1\n",
    "        \n",
    "        if key not in introns: introns[key] = []\n",
    "        assert bp not in introns[key], bp\n",
    "        if bp != -1: introns[key] += [bp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37110\n",
      "169182\n"
     ]
    }
   ],
   "source": [
    "known   = {key: value for key, value in introns.items() if value}\n",
    "missing = {key: value for key, value in introns.items() if not value}\n",
    "print len(known)\n",
    "print len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37110, 70, 4) (37110, 70) 37110\n"
     ]
    }
   ],
   "source": [
    "L = 70\n",
    "bases = ['A', 'C', 'G', 'T']\n",
    "\n",
    "def onehot(seq):\n",
    "    X = np.zeros((len(seq), len(bases)))\n",
    "    for i, char in enumerate(seq):\n",
    "        X[i, bases.index(char)] = 1\n",
    "    return X\n",
    "\n",
    "X, y, chroms = [], [], []\n",
    "for intron, bps in known.items():\n",
    "    chrom, three, strand = intron\n",
    "    if strand == '+':\n",
    "        begin, stop = three - L, three\n",
    "    else:\n",
    "        begin, stop = three, three + L\n",
    "    \n",
    "    # Get features\n",
    "    seq = genome.get_seq(chrom, begin, stop, strand)\n",
    "    if 'N' in seq: seq = seq.replace('N', 'A')\n",
    "    \n",
    "    X += [onehot(seq).reshape(1, L, 4)]\n",
    "\n",
    "    # Make target\n",
    "    _y = np.zeros((stop - begin,))\n",
    "    for bp in bps:\n",
    "        if strand == '+':\n",
    "            bp = L + bp - three\n",
    "        else:\n",
    "            bp = L - bp + three - 1\n",
    "        _y[bp] = 1\n",
    "    y += [_y]\n",
    "    \n",
    "    chroms += [chrom]\n",
    "\n",
    "X, y = np.vstack(X), np.vstack(y)\n",
    "print X.shape, y.shape, len(chroms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4306 7093 25711\n",
      "(25711, 70, 4) (7093, 70, 4) (4306, 70, 4)\n",
      "(25711, 70) (7093, 70) (4306, 70)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(map(lambda x: x == 'chr1', chroms))\n",
    "valid = np.array(map(lambda x: x in ('chr2', 'chr3', 'chr4', 'chr5'),\n",
    "                     chroms))\n",
    "train = np.array([not (t or v) for t, v in zip(test, valid)])\n",
    "print sum(test),  sum(valid), sum(train)\n",
    "\n",
    "X_train, X_valid, X_test = X[train], X[valid], X[test]\n",
    "y_train, y_valid, y_test = y[train], y[valid], y[test]\n",
    "print X_train.shape, X_valid.shape, X_test.shape\n",
    "print y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11768, 70, 4) (10491, 70, 4)\n",
      "(3529, 70, 4) (2703, 70, 4)\n",
      "(36202, 70, 4) (9796, 70, 4) (36202, 1) (9796, 1)\n",
      "(2703, 70, 4)\n"
     ]
    }
   ],
   "source": [
    "divide = 25\n",
    "\n",
    "X_dist = X_train[np.sum(y_train[:, L-divide:], axis = 1) == 0]\n",
    "X_prox = X_train[np.sum(y_train[:, :L-divide], axis = 1) == 0]\n",
    "print X_dist.shape, X_prox.shape\n",
    "\n",
    "dim = min(X_prox.shape[0], X_dist.shape[0])\n",
    "X_aug = np.hstack([X_prox[:dim, :L-27], X_dist[:dim, L-27:]])\n",
    "\n",
    "v_X_dist = X_valid[np.sum(y_valid[:, L-divide:], axis = 1) == 0]\n",
    "v_X_prox = X_valid[np.sum(y_valid[:, :L-divide], axis = 1) == 0]\n",
    "print v_X_dist.shape, v_X_prox.shape\n",
    "\n",
    "dim = min(v_X_prox.shape[0], v_X_dist.shape[0])\n",
    "v_X_aug = np.hstack([v_X_prox[:dim, :L-27], v_X_dist[:dim, L-27:]])\n",
    "\n",
    "X_T = np.vstack([X_train, X_aug])\n",
    "X_V = np.vstack([X_valid, v_X_aug])\n",
    "y_T = np.hstack([np.ones(X_train.shape[0]), np.zeros(X_aug.shape[0])]).reshape(-1, 1)\n",
    "y_V = np.hstack([np.ones(X_valid.shape[0]), np.zeros(v_X_aug.shape[0])]).reshape(-1, 1)\n",
    "print X_T.shape, X_V.shape, y_T.shape, y_V.shape\n",
    "print v_X_aug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute PWM as sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5543.   4025.   6580.  30750.   7524.   8726.   7128.]\n",
      " [ 15038.   6727.  13676.   3718.  13751.  12028.  11222.]\n",
      " [  6480.   5016.   8802.   1699.   6906.   6065.   7984.]\n",
      " [ 11990.  23283.   9993.   2884.  10870.  12232.  12717.]]\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "counts = np.zeros((2*K+1, 4))\n",
    "for target, seq in zip(y_train, X_train):\n",
    "    for bp in np.nonzero(target)[0]:\n",
    "        if 0 > bp-K or bp+K+1 > seq.shape[0]: continue\n",
    "        counts = counts + seq[bp-K: bp+K+1]\n",
    "print counts.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.train_auc = []\n",
    "        self.train_match = []\n",
    "        self.valid_auc = []\n",
    "        self.valid_match = []\n",
    "        \n",
    "    def train(self, X_train, X_valid,\n",
    "              y_train, y_valid, PATIENCE = 15, EPOCHS = 1000):\n",
    "        print model.summary()\n",
    "        for i in range(EPOCHS):\n",
    "            model.fit(X_train, y_train, epochs = 1, verbose = 0, batch_size = 8)\n",
    "            print model.evaluate(X_valid, y_valid, verbose = 0)\n",
    "    \n",
    "    def predict(X):\n",
    "        return self.model.predict(X)\n",
    "                \n",
    "    def _evaluate(self, X_train, X_valid, y_train, y_valid):\n",
    "        valid_preds = self.model.predict_proba(X_valid, verbose=0)\n",
    "        train_preds = self.model.predict_proba(X_train, verbose=0)\n",
    "        self.valid_match += [matching(valid_preds, y_valid)[0]\n",
    "                             / float(y_valid.shape[0])]\n",
    "        self.train_match += [matching(train_preds, y_train)[0]\n",
    "                             / float(y_train.shape[0])]\n",
    "        self.valid_auc += [metrics.roc_auc_score(y_valid.flatten(),\n",
    "                                                 valid_preds.flatten())]\n",
    "        self.train_auc += [metrics.roc_auc_score(y_train.flatten(),\n",
    "                                                 train_preds.flatten())]\n",
    "    \n",
    "    def _plot_scores(self):\n",
    "        plt.plot(self.valid_match, label = 'Validation')\n",
    "        plt.plot(self.train_match, label = 'Training')\n",
    "        plt.ylabel('Match')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot(self.valid_auc, label = 'Validation')\n",
    "        plt.plot(self.train_auc, label = 'Training')\n",
    "        plt.ylabel('auROC')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, LSTM, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_13 (Bidirectio (None, 70, 64)            9472      \n",
      "_________________________________________________________________\n",
      "bidirectional_14 (Bidirectio (None, 64)                24832     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 34,369\n",
      "Trainable params: 34,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "0.588152708692\n",
      "0.571887945778\n",
      "0.550657419635\n",
      "0.536019481557\n",
      "0.548814747445\n",
      "0.510352563157\n",
      "0.511352188785\n",
      "0.498894588297\n",
      "0.502466637147\n",
      "0.499237209376\n",
      "0.486951810577\n",
      "0.493278082243\n",
      "0.506189392994\n",
      "0.504602215153\n",
      "0.485833794426\n",
      "0.490494589822\n",
      "0.506073213563\n",
      "0.482457841134\n",
      "0.482252459543\n",
      "0.487758995344\n",
      "0.48776181448\n",
      "0.476713384205\n",
      "0.485599702502\n",
      "0.485942847245\n",
      "0.476032163353\n",
      "0.482683859245\n",
      "0.482602569024\n",
      "0.469818105998\n",
      "0.467539722796\n",
      "0.472746365603\n",
      "0.467042169215\n",
      "0.474698050624\n",
      "0.46485351382\n",
      "0.469662824885\n",
      "0.472886503376\n",
      "0.460252140385\n",
      "0.477826990732\n",
      "0.480362719397\n",
      "0.466316901455\n",
      "0.490835311049\n",
      "0.466491135031\n",
      "0.473522037475\n",
      "0.475435580512\n",
      "0.472230779475\n",
      "0.557678266331\n",
      "0.465141172699\n",
      "0.466748859406\n",
      "0.475509013349\n",
      "0.478968707687\n",
      "0.462827393708\n",
      "0.467054983252\n",
      "0.465311506625\n",
      "0.47532541554\n",
      "0.460831835653\n",
      "0.462932324412\n",
      "0.46668815137\n",
      "0.482170828657\n",
      "0.465689716703\n",
      "0.471245619546\n",
      "0.470112273381\n",
      "0.474743499153\n",
      "0.524002729216\n",
      "0.472766371321\n",
      "0.505944492392\n",
      "0.467661359447\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True,\n",
    "                             dropout = 0.15, recurrent_dropout = 0.05),\n",
    "                            input_shape = (L, 4)))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = False,\n",
    "                             dropout = 0.15, recurrent_dropout = 0.05)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.001,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.999,\n",
    "                                        epsilon=1e-08,\n",
    "                                        decay=0.0))\n",
    "\n",
    "ModelTrainer(model).train(X_T, X_V, y_T, y_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('../models/augmented.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
